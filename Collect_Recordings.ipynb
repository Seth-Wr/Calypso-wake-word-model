{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a2f3334-d2ab-475b-a270-594041bfec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------\n",
    "# Constants (match training)\n",
    "# -----------------------\n",
    "SAMPLE_RATE = 16000\n",
    "NUM_SAMPLES = 20000\n",
    "NUM_MELS = 40\n",
    "FRAME_LENGTH = 512\n",
    "FRAME_STEP = 160\n",
    "FFT_LENGTH = 512\n",
    "FMIN = 80.0\n",
    "FMAX = 7600.0\n",
    "\n",
    "# -----------------------\n",
    "# Preprocessing: waveform → log-mel\n",
    "# -----------------------\n",
    "def waveform_to_log_mel(waveform):\n",
    "    #Convert wav file data into tensors as a spectrogram\n",
    "    x = tf.convert_to_tensor(waveform, dtype=tf.float32)\n",
    "    x = tf.concat([x[:1], x[1:] - 0.97 * x[:-1]], 0)\n",
    "\n",
    "    stft = tf.signal.stft(\n",
    "        x,\n",
    "        frame_length=FRAME_LENGTH,\n",
    "        frame_step=FRAME_STEP,\n",
    "        fft_length=FFT_LENGTH,\n",
    "        window_fn=tf.signal.hann_window\n",
    "    )\n",
    "    mag = tf.abs(stft)\n",
    "\n",
    "    mel_weight = tf.signal.linear_to_mel_weight_matrix(\n",
    "        NUM_MELS, mag.shape[-1], SAMPLE_RATE, FMIN, FMAX)\n",
    "    mel = tf.matmul(mag, mel_weight)\n",
    "\n",
    "    log_mel = tf.math.log(mel + 1e-6)\n",
    "    mean = tf.math.reduce_mean(log_mel)\n",
    "    std = tf.math.reduce_std(log_mel) + 1e-6\n",
    "    log_mel = (log_mel - mean) / std\n",
    "     #add batch size dimension as model expects this when given data\n",
    "    return tf.expand_dims(log_mel, -1)  # (time, mels, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098b3847-ad77-4743-8a69-fee84966d8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] MacBook Pro Microphone\n"
     ]
    }
   ],
   "source": [
    "# check hardware for mic\n",
    "p = pyaudio.PyAudio()\n",
    "for i in range(p.get_device_count()):\n",
    "    info = p.get_device_info_by_index(i)\n",
    "    if info[\"maxInputChannels\"] > 0:\n",
    "        print(f\"[{i}] {info['name']}\")\n",
    "p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdabe246-3b68-4971-83a5-e3f0494c935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded: /Users/sethwright/Documents/audio-model/output/saved_model.keras\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Load trained Keras model\n",
    "# -----------------------\n",
    "MODEL_PATH=\"/Users/sethwright/Documents/audio-model/output/saved_model.keras\"\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile =False, safe_mode=False)\n",
    "print(\"✅ Model loaded:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390ee6c-576f-4996-a1e4-9174eea0c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load wav files 16000 sample rate\n",
    "def load_test_clip(filepath):\n",
    "    waveform, sr = sf.read(filepath, dtype=\"float32\")\n",
    "\n",
    "    # Resample if needed\n",
    "    if sr != SAMPLE_RATE:\n",
    "        print(f\"Resampling from {sr} → {SAMPLE_RATE}\")\n",
    "        waveform = tf.signal.resample(waveform, int(len(waveform) * SAMPLE_RATE / sr)).numpy()\n",
    "\n",
    "    # Mono\n",
    "    if len(waveform.shape) > 1:\n",
    "        waveform = np.mean(waveform, axis=1)\n",
    "\n",
    "    # Pad or trim to expected length\n",
    "    waveform = waveform[:NUM_SAMPLES]\n",
    "    if len(waveform) < NUM_SAMPLES:\n",
    "        waveform = np.pad(waveform, (0, NUM_SAMPLES - len(waveform)))\n",
    "\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebaad45-934f-46c0-9d88-3d4b8572002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number is just to help track files start at 0\n",
    "y = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2d7f4217-84e2-4423-9ab4-670c7fa73b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎙️  Recording 1.25 s sample...\n",
      "💾 Saved recording to: test_recording693_positive.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "DURATION_SECONDS = 1.25\n",
    "NUM_SAMPLES = int(SAMPLE_RATE * DURATION_SECONDS)\n",
    "DEVICE_INDEX = 0  # change to your mic index\n",
    "\n",
    "def record_clip(x):\n",
    "    save_path=\"test_recording\"+str(x)+\"_positive.wav\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=1,\n",
    "                    rate=SAMPLE_RATE,\n",
    "                    input=True,\n",
    "                    input_device_index=DEVICE_INDEX,\n",
    "                    frames_per_buffer=1024)  # smaller buffer = more reliable\n",
    "\n",
    "    print(\"🎙️  Recording 1.25 s sample...\")\n",
    "\n",
    "    frames = []\n",
    "    for _ in range(int(SAMPLE_RATE / 1024 * DURATION_SECONDS)):\n",
    "        data = stream.read(1024, exception_on_overflow=False)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Join frames & convert to float32 waveform\n",
    "    audio_bytes = b\"\".join(frames)\n",
    "    waveform = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "\n",
    "    # Fix length to NUM_SAMPLES\n",
    "    waveform = waveform[:NUM_SAMPLES]\n",
    "    if len(waveform) < NUM_SAMPLES:\n",
    "        waveform = np.pad(waveform, (0, NUM_SAMPLES - len(waveform)))\n",
    "\n",
    "    # Save to WAV file\n",
    "    sf.write(save_path, waveform, SAMPLE_RATE)\n",
    "    print(f\"💾 Saved recording to: {save_path}\")\n",
    "   \n",
    "\n",
    "    return waveform\n",
    "#us while loop to get background noise and put a break point when y gets to desried number\n",
    "# Run it\n",
    "#while True:\n",
    "   # y+= 1 \n",
    "   # record_clip(y)\n",
    "    \n",
    "    #break\n",
    "    #record one clip at time and save it\n",
    "record_clip(y) \n",
    "y +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4758f99-169d-4e21-9cc6-6aba9ec7983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "\n",
      "Model raw output: 0.0016\n",
      "No wake word.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# Run inference\n",
    "# -----------------------\n",
    "\n",
    "waveform = load_test_clip(\"/Users/sethwright/Documents/audio-model/test_recording.wav\")\n",
    "spec = waveform_to_log_mel(waveform)\n",
    "spec = tf.expand_dims(spec, 0)  # add batch dim\n",
    "\n",
    "pred = model.predict(spec)[0][0]\n",
    "print(f\"\\nModel raw output: {pred:.4f}\")\n",
    "print(\"Wake word detected!\" if pred > 0.5 else \"No wake word.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio-kernel",
   "language": "python",
   "name": "audio-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
